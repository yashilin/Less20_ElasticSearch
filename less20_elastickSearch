# 2. Создайте KSQL Stream WIKILANG

Посмотрите какие топики есть сейчас в системе, и на основе того, в котором вы видите максимальный объем данных создайте stream по имени WIKILANG который фильтрует правки только в разделах национальных языков, кроме английского (поле channel вида #ru.wikipedia), который сделали не боты.

Stream должен содержать следующие поля: createdat, channel, username, wikipage, diffurl

------------------------------------------------------

ksql> CREATE STREAM WIKILANG AS select 
>   createdat 
>   , channel 
>   , username
>   , wikipage
>   , diffurl 
>FROM WIKIPEDIANOBOT 
>where isbot = false
>and channel not like '%#en.%'
>;

 Message             
---------------------
 Executing statement 
---------------------

# 3. Мониторинг WIKILANG

После 1-2 минут работы откройте Confluent Control Center и сравните пропускную способность топиков WIKILANG и WIKIPEDIANOBOT, какие числа вы видите?

- В KSQL CLI получите текущую статистику вашего стрима: describe extended wikilang;  

Приложите полный ответ на предыдущий запрос к ответу на задание.
-------------------------------------------------------

ksql> describe extended wikilang;

Name                 : WIKILANG
Type                 : STREAM
Key field            : 
Key format           : STRING
Timestamp field      : Not set - using <ROWTIME>
Value format         : AVRO
Kafka topic          : WIKILANG (partitions: 2, replication: 2)

 Field     | Type                      
---------------------------------------
 ROWTIME   | BIGINT           (system) 
 ROWKEY    | VARCHAR(STRING)  (system) 
 CREATEDAT | BIGINT                    
 CHANNEL   | VARCHAR(STRING)           
 USERNAME  | VARCHAR(STRING)           
 WIKIPAGE  | VARCHAR(STRING)           
 DIFFURL   | VARCHAR(STRING)           
---------------------------------------

Queries that write from this STREAM
-----------------------------------
CSAS_WIKILANG_7 : CREATE STREAM WIKILANG WITH (KAFKA_TOPIC='WIKILANG', PARTITIONS=2, REPLICAS=2) AS SELECT
  WIKIPEDIANOBOT.CREATEDAT "CREATEDAT",
  WIKIPEDIANOBOT.CHANNEL "CHANNEL",
  WIKIPEDIANOBOT.USERNAME "USERNAME",
  WIKIPEDIANOBOT.WIKIPAGE "WIKIPAGE",
  WIKIPEDIANOBOT.DIFFURL "DIFFURL"
FROM WIKIPEDIANOBOT WIKIPEDIANOBOT
WHERE ((WIKIPEDIANOBOT.ISBOT = false) AND (NOT (WIKIPEDIANOBOT.CHANNEL LIKE '%#en.%')))
EMIT CHANGES;

For query topology and execution plan please run: EXPLAIN <QueryId>

Local runtime statistics
------------------------
messages-per-sec:         0   total-messages:      3741     last-message: 2020-03-05T19:42:56.62Z

(Statistics of the local KSQL server interaction with the Kafka topic WIKILANG)



- В KSQL CLI получите текущую статистику WIKIPEDIANOBOT: descrbie extended wikipedianobot;  

Приложите раздел Local runtime statistics к ответу на задание.  

-------------------------------------------
ksql> describe extended wikipedianobot;

Name                 : WIKIPEDIANOBOT
Type                 : STREAM
Key field            : 
Key format           : STRING
Timestamp field      : Not set - using <ROWTIME>
Value format         : AVRO
Kafka topic          : WIKIPEDIANOBOT (partitions: 2, replication: 2)


Local runtime statistics
------------------------
messages-per-sec:         0   total-messages:       18899     last-message: 2020-03-05T12:37:54.495Z

(Statistics of the local KSQL server interaction with the Kafka topic WIKIPEDIANOBOT)

Почему для wikipedianobot интерфейс показывает также consumer-* метрики?

Ответ:  Потому, что наш стрим сделан на основании WIKIPEDIANOBOT и является для него потребителем.
У wikipedianobot есть consumer WIKIPEDIANOBOT-consumer


# 4. Добавьте данные из стрима WIKILANG в ElasticSearch
a) Опишите что делает каждая из этих операций?  
- Добавьте mapping - запустите скрипт set_elasticsearch_mapping_lang.sh
     Ответ: Создает маппинг, описывает структуру данных
- Добавьте Kafka Connect - запустите submit_elastic_sink_lang_config.sh

[admin@localhost cp-demo]$ ./submit_elastic_sink_lang_config.sh 
{"name":"elasticsearch-ksql-lang","config":{"connector.class":"io.confluent.connect.elasticsearch.ElasticsearchSinkConnector","consumer.interceptor.classes":"io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor","topics":"WIKILANG","topic.index.map":"WIKILANG:wikilang","connection.url":"http://elasticsearch:9200","type.name":"wikichange_short","key.ignore":"true","key.converter.schema.registry.url":"https://schemaregistry:8085","value.converter":"io.confluent.connect.avro.AvroConverter","value.converter.schema.registry.url":"https://schemaregistry:8085","schema.ignore":"true","name":"elasticsearch-ksql-lang"},"tasks":[],"type":"sink"}

	 Ответ: Создает соединение, использует созданный маппинг.
- Добавьте index-pattern - Kibana UI -> Management -> Index patterns -> Create Index Pattern -> Index name or pattern: wikilang -> кнопка Create
     Ответ: Описывает индексы для быстрого получения данных.
 
б) Зачем Elasticsearch нужен mapping чтобы принять данные?  

    Принимаемые данные могут быть как String и обрабатыаются как полнотестовый поля, так же идет описание полей содержащие
    даты, чила , обработка динамически добавляемых полей и.т.д

в) Что дает index-pattern?

	Ответ: index-pattern описывает имя индекса из которого строятся запросы для получения данных.


# 5. Создайте отчет "Топ10 национальных разделов" на базе индекса wikilang
- Kibana UI -> Visualize -> + -> Data Table -> выберите индекс wikilang
- Select bucket type -> Split Rows, Aggregation -> Terms, Field -> CHANNEL.keyword, Size -> 10, нажмите кнопку Apply changes (выглядит как кнопка Play)
- Сохраните визуализацию под удобным для вас именем

Что вы увидели в отчете?
Ответ:  В отчете мы видим посчет (count) записей с группировкой по CHANNEL,
И сортировка по колличеству записей 

#commons.wikimedia	2,754
#de.wikipedia	1,118
#fr.wikipedia	1,098
#es.wikipedia	888
#ru.wikipedia	614
#it.wikipedia	478
#zh.wikipedia	230
#uk.wikipedia	176
#eo.wikipedia 	72
#eu.wikipedia   38


- Нажав маленьку круглую кнопку со стрелкой вверх под отчетом, вы сможете запросить не только таблицу, но и запрос на Query DSL которым он получен.

Приложите тело запроса к заданию.


5.2 Приложите тело запроса к заданию:

{
  "size": 0,
  "query": {
    "bool": {
      "must": [
        {
          "match_all": {}
        },
        {
          "range": {
            "CREATEDAT": {
              "gte": 1566211108657,
              "lte": 1566212008657,
              "format": "epoch_millis"
            }
          }
        }
      ],
      "must_not": []
    }
  },
  "_source": {
    "excludes": []
  },
  "aggs": {
    "2": {
      "terms": {
        "field": "CHANNEL.keyword",
        "size": 10,
        "order": {
          "_count": "desc"
        }
      }
    }
  }
}
